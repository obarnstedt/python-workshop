{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obarnstedt/LINdoscope2023/blob/main/notebooks/DLC_Colab_VideoAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK255E7YoEIt"
      },
      "source": [
        "# DeepLabCut Toolbox - Colab for standard (single animal) projects!\n",
        "This notebook is a modified copy from [Github](https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/master/examples/COLAB/COLAB_YOURDATA_TrainNetwork_VideoAnalysis.ipynb), originally written by Mackenzie Mathis; publication: Mathis et al 2018, https://doi.org/10.1038/s41593-018-0209-y.\n",
        "\n",
        "It has been edited for the 2023 EMBO practical course LINdoscope: https://www.lindoscope.com.\n",
        "\n",
        "https://github.com/DeepLabCut/DeepLabCut\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/71523c879284afa1c51b8489491f06d24d1ff02d75dca9f71078535ee6b1978e/68747470733a2f2f696d616765732e73717561726573706163652d63646e2e636f6d2f636f6e74656e742f76312f3537663664353163396637343536366635356563663237312f313632383235303030343232392d4b565944374a4a5648594546444a33324c39564a2f444c436c6f676f323032312e6a70673f666f726d61743d3130303077)\n",
        "\n",
        "This notebook illustrates how to use colab to:\n",
        "- load a pretrained model\n",
        "- analyze novel videos, filter data, create videos\n",
        "\n",
        "This notebook demonstrates the necessary steps to use DeepLabCut for your own project. This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper.\n",
        "\n",
        "Nath\\*, Mathis\\* et al.: Using DeepLabCut for markerless pose estimation during behavior across species. Nature Protocols, 2019.\n",
        "\n",
        "Paper: https://www.nature.com/articles/s41596-019-0176-0\n",
        "\n",
        "Pre-print: https://www.biorxiv.org/content/biorxiv/early/2018/11/24/476531.full.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txoddlM8hLKm"
      },
      "source": [
        "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(this will take a few minutes to install all the dependences!)\n",
        "!pip install deeplabcut"
      ],
      "metadata": {
        "id": "vLztNBNphoiN",
        "outputId": "3e4da92e-6671-4143-cfd3-6ec71d3d4605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deeplabcut\n",
            "  Downloading deeplabcut-2.3.5-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dlclibrary (from deeplabcut)\n",
            "  Downloading dlclibrary-0.0.4-py3-none-any.whl (15 kB)\n",
            "Collecting filterpy>=1.4.4 (from deeplabcut)\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ruamel.yaml>=0.15.0 (from deeplabcut)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.4.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.4.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.56.4)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (3.7.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.23.5)\n",
            "Requirement already satisfied: pandas!=1.5.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.5.3)\n",
            "Requirement already satisfied: scikit-image>=0.17 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.10.1)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (0.14.0)\n",
            "Requirement already satisfied: tables>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (3.8.0)\n",
            "Collecting torch<=1.12 (from deeplabcut)\n",
            "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorpack>=0.11 (from deeplabcut)\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (4.66.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (6.0.1)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from deeplabcut) (9.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (1.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (2.31.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut) (2.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->deeplabcut) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->deeplabcut) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.0.1->deeplabcut) (2023.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.15.0->deeplabcut)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17->deeplabcut) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17->deeplabcut) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->deeplabcut) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->deeplabcut) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11->deeplabcut) (0.5.3)\n",
            "Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (0.29.36)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (2.8.5)\n",
            "Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (2.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut) (9.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (2.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (0.9.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (1.0.5)\n",
            "Collecting msgpack-numpy>=0.4.4.2 (from tensorpack>=0.11->deeplabcut)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (23.2.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut) (5.9.5)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1.0->deeplabcut) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<=1.12->deeplabcut) (4.7.1)\n",
            "Collecting huggingface-hub (from dlclibrary->deeplabcut)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->dlclibrary->deeplabcut) (2023.7.22)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=4d4c8a3159bfdfafaa803afd963785dfb5c5dbb2f3585af862fe733b221c36fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: torch, ruamel.yaml.clib, msgpack-numpy, tensorpack, ruamel.yaml, huggingface-hub, filterpy, dlclibrary, deeplabcut\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deeplabcut-2.3.5 dlclibrary-0.0.4 filterpy-1.4.5 huggingface-hub-0.16.4 msgpack-numpy-0.4.8 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 tensorpack-0.11 torch-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25wSj6TlVclR"
      },
      "source": [
        "**(Be sure to click \"RESTART RUNTIME\" if it is displayed above above before moving on !)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-nlTkri4HZ"
      },
      "source": [
        "## Link your Google Drive\n",
        "\n",
        "1. First, add a shortcut to a pretrained DLC model into you google drive. To do so, right click on the desired folder -> Organise -> Add shortcut -> My Drive -> Add\n",
        "\n",
        "2. Next, add [a shortcut to] a folder with videos that you want to analyse to your Google Drive\n",
        "\n",
        "3. Now, let's link to your GoogleDrive. Run the cell below and follow the authorization instructions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KS4Q4UkR9rgG",
        "outputId": "dc99309d-283a-43a0-c0b1-fc218075d705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3K9Ndy1beyfG",
        "outputId": "ca678019-67be-49c5-c537-f87a9932850d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DLC 2.3.5...\n",
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import matplotlib\n",
        "import os\n",
        "import deeplabcut\n",
        "deeplabcut.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: shorten videos\n",
        "Add below a path to a video you want to shorten. Enter length of a desired video."
      ],
      "metadata": {
        "id": "8Tw8DXi-TpJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE EDIT THESE:\n",
        "videofile_path = '/content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/Basler acA780-75gm (22611479)_20190218_151620616.mp4'\n",
        "length = 30 # desired length in seconds\n",
        "\n",
        "# Edit these if needed\n",
        "framerate = 75\n",
        "outsuffix = '_short'\n",
        "\n",
        "# Do not edit these\n",
        "outfolder = os.path.join(os.path.dirname(videofile_path), 'DLC_'+os.path.basename(videofile_path).split('.mp4')[0])\n",
        "if not os.path.exists(outfolder):\n",
        "  os.makedirs(outfolder)\n",
        "\n",
        "outpath = os.path.join(outfolder, os.path.basename(videofile_path).split('.mp4')[0]+outsuffix+'.mp4')"
      ],
      "metadata": {
        "id": "EXohJHPdRfnu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_video(path_in, path_out, stop_frame, start_frame=0):\n",
        "  import cv2\n",
        "  from tqdm import tqdm\n",
        "  cap = cv2.VideoCapture(path_in)\n",
        "  cap.set(1, start_frame)\n",
        "  frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "  vid_trimmed = cv2.VideoWriter(path_out, cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "                                fps, (frame_width, frame_height))\n",
        "  vidlength = stop_frame - start_frame\n",
        "  i = start_frame\n",
        "\n",
        "  print('Trimming video...')\n",
        "  with tqdm(total=vidlength) as pbar:\n",
        "      while cap.isOpened():\n",
        "          _, current_frame = cap.read()\n",
        "          if current_frame is None or i>=stop_frame:\n",
        "              break\n",
        "          vid_trimmed.write(current_frame)\n",
        "          pbar.update(1)\n",
        "          i+=1\n",
        "  cap.release()\n",
        "  vid_trimmed.release()\n",
        "\n",
        "  return path_out"
      ],
      "metadata": {
        "id": "LFUnN3AExpvp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  trim_video(videofile_path, outpath, framerate*length)"
      ],
      "metadata": {
        "id": "SbvTZ5IPz8po",
        "outputId": "4ca3ef19-61fb-43a7-ccf0-ba1f66ae0164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimming video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2250/2250 [00:10<00:00, 210.11it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frnj1RVDyEqs"
      },
      "source": [
        "## Setup your project variables\n",
        "Modify variables **PretrainedModelFolderName** and **VideoFolderName** to names of a folder with a pretrained model and to the videos you would like to analyse, respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vhENAlQnFENJ",
        "outputId": "848de16d-6bdb-42ce-bbfa-d3c3466ae5c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/LINdoscope2023_analysis/DLC_models/MouseBody-Barnstedt-2019-09-09/config.yaml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# PLEASE EDIT THESE:\n",
        "PretrainedModelFolderName = 'MouseBody-Barnstedt-2019-09-09'\n",
        "VideoType = 'mp4'\n",
        "\n",
        "#don't edit these:\n",
        "videofile_path = [outpath] #Enter the list of videos or folder to analyze.\n",
        "videofile_path\n",
        "\n",
        "#This creates a path variable that links to your google drive copy\n",
        "#No need to edit this, as you set it up before:\n",
        "path_config_file = '/content/drive/My Drive/LINdoscope2023_analysis/DLC_models/'+PretrainedModelFolderName+'/config.yaml'\n",
        "path_config_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFLSKKfoEJk"
      },
      "source": [
        "## Start Analyzing videos\n",
        "This function analyzes your videos.\n",
        "\n",
        "The results are stored in hd5 file in the same directory where the video resides. The data is also exported in comma-separated values format (.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Y_LZiS_0oEJl",
        "outputId": "d23fa030-b8d7-4da5-9d12-70198e0792a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using snapshot-1030000 for model /content/drive/My Drive/LINdoscope2023_analysis/DLC_models/MouseBody-Barnstedt-2019-09-09/dlc-models/iteration-1/MouseBodySep9-trainset95shuffle1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to analyze %  /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4\n",
            "Loading  /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4\n",
            "Duration of video [s]:  30.0 , recorded with  75.0 fps!\n",
            "Overall # of frames:  2250  found with (before cropping) frame dimensions:  782 582\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2250/2250 [01:29<00:00, 25.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616...\n",
            "Saving csv poses!\n",
            "The videos are analyzed. Now your research can truly start! \n",
            " You can create labeled videos with 'create_labeled_video'\n",
            "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DLC_resnet50_MouseBodySep9shuffle1_1030000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "deeplabcut.analyze_videos(path_config_file, videofile_path, videotype=VideoType, shuffle=1, save_as_csv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrkIDiciSWH1"
      },
      "source": [
        "You can also now filter your data to smooth any small jitters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "X8SmVAIkSbLp",
        "outputId": "41163161-d5de-4acf-8489-3190758cf54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering with median model /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4\n",
            "Saving filtered csv poses!\n"
          ]
        }
      ],
      "source": [
        "deeplabcut.filterpredictions(path_config_file, videofile_path, videotype=VideoType, shuffle=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GTiuJESoEKH"
      },
      "source": [
        "## Plot the trajectories of the analyzed videos:\n",
        "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gX21zZbXoEKJ",
        "outputId": "033bf078-2cb7-44d3-d605-0730bb58c542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading  /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4 and data.\n",
            "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "deeplabcut.plot_trajectories(path_config_file, videofile_path, videotype=VideoType, shuffle=1, filtered=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqaCw15v8EmB"
      },
      "source": [
        "Now you can look at the plot-poses file and check the \"plot-likelihood.png\" might want to change the \"p-cutoff\" in the config.yaml file so that you have only high confidnece points plotted in the video. i.e. ~0.8 or 0.9. The current default is 0.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCrUvQIvoEKD"
      },
      "source": [
        "## Create labeled video\n",
        "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6aDF7Q7KoEKE",
        "outputId": "aa524bcc-26d6-4df1-f782-e2191b2fd473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to process video: /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4\n",
            "Loading /content/drive/My Drive/LINdoscope2023_analysis/sample_data/2P_dCA1_treadmill/DLC_Basler acA780-75gm (22611479)_20190218_151620616/Basler acA780-75gm (22611479)_20190218_151620616_short.mp4 and data.\n",
            "Duration of video [s]: 30.0, recorded with 75 fps!\n",
            "Overall # of frames: 2250 with cropped frame dimensions: 782 582\n",
            "Generating frames and creating video.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2250/2250 [00:16<00:00, 140.25it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "deeplabcut.create_labeled_video(path_config_file,videofile_path, videotype=VideoType, shuffle=1, filtered=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j4ptI2cWcd44"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}